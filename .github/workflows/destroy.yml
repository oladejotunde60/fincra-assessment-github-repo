name: Destroy Flask EKS Infrastructure

on:
  workflow_dispatch:
    inputs:
      confirm_destroy:
        description: 'Type "destroy" to confirm deletion of all resources'
        required: true
        type: string
      delete_ecr_images:
        description: 'Delete all ECR images before destroying'
        required: true
        type: boolean
        default: true

env:
  AWS_REGION: eu-west-1
  EKS_CLUSTER_NAME: fincra-test-eks-cluster
  ECR_REPOSITORY: flask-app
  TERRAFORM_VERSION: 1.5.7

jobs:
  validate-destroy:
    name: Validate Destroy Request
    runs-on: ubuntu-latest
    outputs:
      should_proceed: ${{ steps.validate.outputs.should_proceed }}
    
    steps:
      - name: Validate confirmation input
        id: validate
        run: |
          if [ "${{ github.event.inputs.confirm_destroy }}" = "destroy" ]; then
            echo "âœ… Destroy confirmation validated"
            echo "should_proceed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Destroy confirmation failed. You must type 'destroy' to proceed."
            echo "should_proceed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  cleanup-kubernetes:
    name: Cleanup Kubernetes Resources
    runs-on: ubuntu-latest
    needs: validate-destroy
    if: needs.validate-destroy.outputs.should_proceed == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
        continue-on-error: true

      - name: Delete Flask App Deployment
        run: |
          echo "Deleting Flask application resources..."
          kubectl delete namespace flask-app --ignore-not-found=true --timeout=5m || true
          echo "âœ… Kubernetes resources cleanup completed"
        continue-on-error: true

      - name: Delete AWS Load Balancer Controller
        run: |
          echo "Deleting AWS Load Balancer Controller..."
          kubectl delete namespace aws-load-balancer-controller --ignore-not-found=true --timeout=5m || true
          echo "âœ… Load Balancer Controller cleanup completed"
        continue-on-error: true

      - name: Wait for LoadBalancers to be deleted
        run: |
          echo "Waiting for AWS Load Balancers to be cleaned up..."
          sleep 60
          echo "âœ… Wait completed"
        continue-on-error: true

  cleanup-ecr:
    name: Cleanup ECR Images
    runs-on: ubuntu-latest
    needs: validate-destroy
    if: |
      needs.validate-destroy.outputs.should_proceed == 'true' && 
      github.event.inputs.delete_ecr_images == 'true'
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete all ECR images
        run: |
          echo "Deleting all images from ECR repository: ${{ env.ECR_REPOSITORY }}"
          
          # Get all image digests
          IMAGE_DIGESTS=$(aws ecr list-images \
            --repository-name ${{ env.ECR_REPOSITORY }} \
            --region ${{ env.AWS_REGION }} \
            --query 'imageIds[*]' \
            --output json 2>/dev/null || echo "[]")
          
          if [ "$IMAGE_DIGESTS" != "[]" ] && [ ! -z "$IMAGE_DIGESTS" ]; then
            echo "Found images to delete"
            aws ecr batch-delete-image \
              --repository-name ${{ env.ECR_REPOSITORY }} \
              --region ${{ env.AWS_REGION }} \
              --image-ids "$IMAGE_DIGESTS" || true
            echo "âœ… ECR images deleted"
          else
            echo "â„¹ï¸  No images found or repository doesn't exist"
          fi
        continue-on-error: true

  terraform-destroy:
    name: Terraform Destroy
    runs-on: ubuntu-latest
    needs: [validate-destroy, cleanup-kubernetes]
    if: needs.validate-destroy.outputs.should_proceed == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false

      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform

      - name: Import Existing Resources (if needed)
        run: |
          set +e  # Don't exit on error
          
          echo "Attempting to import existing resources into state..."
          
          # Import ECR Repository
          terraform import -input=false aws_ecr_repository.flask_app flask-app 2>/dev/null
          
          # Import EKS Cluster
          terraform import -input=false aws_eks_cluster.main fincra-test-eks-cluster 2>/dev/null
          
          # Import IAM Cluster Role
          terraform import -input=false aws_iam_role.eks_cluster fincra-test-eks-cluster-cluster-role 2>/dev/null
          
          # Import Fargate Pod Execution Role
          terraform import -input=false aws_iam_role.fargate_pod_execution fincra-test-eks-cluster-fargate-pod-execution-role 2>/dev/null
          
          # Import AWS Load Balancer Controller IAM Policy
          POLICY_ARN=$(aws iam list-policies --query "Policies[?PolicyName=='fincra-test-eks-cluster-AWSLoadBalancerControllerIAMPolicy'].Arn" --output text 2>/dev/null)
          if [ ! -z "$POLICY_ARN" ]; then
            terraform import -input=false aws_iam_policy.aws_load_balancer_controller "$POLICY_ARN" 2>/dev/null
          fi
          
          echo "âœ… Import attempts completed (errors are normal if resources don't exist)"
          set -e
        working-directory: ./terraform
        continue-on-error: true

      - name: Terraform Destroy Plan
        run: |
          terraform plan -destroy -no-color -out=destroy.tfplan
          echo "ðŸ“‹ Destroy plan created. Review above output."
        working-directory: ./terraform

      - name: Terraform Destroy
        run: |
          echo "ðŸ—‘ï¸  Starting infrastructure destruction..."
          terraform apply -auto-approve destroy.tfplan
          echo "âœ… Terraform destroy completed"
        working-directory: ./terraform

      - name: Verify Cleanup
        run: |
          echo "Verifying resource cleanup..."
          
          # Check EKS cluster
          if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "âš ï¸  EKS cluster still exists (may be deleting)"
          else
            echo "âœ… EKS cluster deleted"
          fi
          
          # Check ECR repository
          if aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "âš ï¸  ECR repository still exists"
          else
            echo "âœ… ECR repository deleted"
          fi
          
          echo "ðŸŽ‰ Destroy workflow completed!"
        continue-on-error: true

  summary:
    name: Destroy Summary
    runs-on: ubuntu-latest
    needs: [terraform-destroy, cleanup-ecr]
    if: always()
    
    steps:
      - name: Generate Summary
        run: |
          echo "# ðŸ—‘ï¸ Infrastructure Destroy Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Status" >> $GITHUB_STEP_SUMMARY
          echo "- Kubernetes Cleanup: ${{ needs.cleanup-kubernetes.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ECR Cleanup: ${{ needs.cleanup-ecr.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Terraform Destroy: ${{ needs.terraform-destroy.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Resources Destroyed" >> $GITHUB_STEP_SUMMARY
          echo "- EKS Cluster: fincra-test-eks-cluster" >> $GITHUB_STEP_SUMMARY
          echo "- ECR Repository: flask-app" >> $GITHUB_STEP_SUMMARY
          echo "- VPC and networking components" >> $GITHUB_STEP_SUMMARY
          echo "- IAM roles and policies" >> $GITHUB_STEP_SUMMARY
          echo "- Security groups" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.terraform-destroy.result }}" = "success" ]; then
            echo "âœ… **All infrastructure successfully destroyed**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Some resources may still exist. Check logs above.**" >> $GITHUB_STEP_SUMMARY
          fi
